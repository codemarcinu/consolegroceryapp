# ğŸ  Asystent ZakupÃ³w i SpiÅ¼arni v2 - Instrukcja instalacji

## ğŸ“‹ Wymagania systemowe

### Podstawowe wymagania
- **Python 3.8+** 
- **pip3** (menedÅ¼er pakietÃ³w Python)
- **4GB RAM** (minimum dla Ollama)
- **2GB wolnego miejsca** na dysku

### Dla funkcji OCR (opcjonalnie)
- **Tesseract OCR** z polskim pakietem jÄ™zykowym
- **OpenCV** dependencies

## ğŸ”§ Instalacja krok po kroku

### 1. Przygotowanie Å›rodowiska

**Linux (Ubuntu/Debian):**
```bash
# Aktualizacja systemu
sudo apt update && sudo apt upgrade -y

# Python i narzÄ™dzia
sudo apt install python3 python3-pip python3-venv -y

# Tesseract OCR (opcjonalnie - dla funkcji paragonÃ³w)
sudo apt install tesseract-ocr tesseract-ocr-pol -y
sudo apt install libopencv-dev python3-opencv -y
sudo apt install libgl1-mesa-glx libglib2.0-0 -y
```

**Windows:**
```cmd
# 1. Pobierz Python 3.8+ z python.org
# 2. Zainstaluj z opcjÄ… "Add Python to PATH"
# 3. Tesseract (opcjonalnie):
#    - Pobierz z: https://github.com/UB-Mannheim/tesseract/wiki
#    - Zainstaluj do C:\Program Files\Tesseract-OCR
#    - Dodaj do zmiennej PATH
```

**macOS:**
```bash
# Homebrew (jeÅ›li nie masz)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Python i narzÄ™dzia
brew install python3 python3-pip

# Tesseract (opcjonalnie)
brew install tesseract tesseract-lang
```

### 2. Klonowanie repozytorium

```bash
git clone <REPO_URL>
cd asystent-spizarni
```

### 3. Automatyczna instalacja (Rekomendowane)

**Linux/macOS:**
```bash
chmod +x setup.sh
./setup.sh
```

**Windows:**
```cmd
python -m venv venv
venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt
```

### 4. Instalacja Ollama (AI/LLM)

**Linux/macOS:**
```bash
# Instalacja Ollama
curl https://ollama.ai/install.sh | sh

# Uruchomienie serwera Ollama
ollama serve &

# Pobranie modelu Bielik (polski model AI)
ollama pull speakleash/bielik-1.5b-v3.0-instruct

# Test modelu
ollama run speakleash/bielik-1.5b-v3.0-instruct "Witaj! Jestem asystentem spiÅ¼arni."
```

**Windows:**
```cmd
# 1. Pobierz Ollama z: https://ollama.ai/download/windows
# 2. Zainstaluj Ollama
# 3. OtwÃ³rz PowerShell/CMD i uruchom:
ollama pull speakleash/bielik-1.5b-v3.0-instruct
ollama serve
```

### 5. Uruchomienie aplikacji

```bash
# Aktywuj Å›rodowisko wirtualne (jeÅ›li uÅ¼ywasz)
source venv/bin/activate  # Linux/macOS
# lub
venv\Scripts\activate     # Windows

# Uruchom aplikacjÄ™
python main.py
```

## ğŸš€ Pierwsze uruchomienie

### Struktura folderÃ³w (tworzona automatycznie):
```
asystent-spizarni/
â”œâ”€â”€ data/              # Baza danych produktÃ³w
â”œâ”€â”€ paragony/
â”‚   â”œâ”€â”€ nowe/         # Tutaj wrzucaj nowe paragony (zdjÄ™cia)
â”‚   â”œâ”€â”€ przetworzone/ # Przetworzone paragony
â”‚   â””â”€â”€ bledy/        # Paragony z bÅ‚Ä™dami OCR
â””â”€â”€ ...
```

### Konfiguracja aplikacji:
- Plik `data/config.json` jest tworzony automatycznie przy pierwszym uruchomieniu
- MoÅ¼na modyfikowaÄ‡ ustawienia LLM, OCR, interfejsu

## ğŸ“± Workflow uÅ¼ytkowania

### 1. Dodawanie produktÃ³w rÄ™cznie
- Opcja 1: Dodaj produkt (szybko)
- AI automatycznie sugeruje kategoriÄ™ i datÄ™ waÅ¼noÅ›ci

### 2. Automatyczne przetwarzanie paragonÃ³w
```
ZrÃ³b zdjÄ™cie paragonu â†’ Skopiuj do paragony/nowe/ â†’ 
Opcja 2: PrzetwÃ³rz paragony â†’ Opcja 3: Importuj do spiÅ¼arni
```

### 3. Codzienne zarzÄ…dzanie
- **Rano**: SprawdÅº wygasajÄ…ce produkty (automatycznie przy starcie)
- **Podczas gotowania**: Opcja 5 - Szybko znajdÅº i oznacz produkty
- **Planowanie**: Opcja 6 - AI podpowie przepisy na podstawie spiÅ¼arni

## ğŸ”§ RozwiÄ…zywanie problemÃ³w

### Problem: "BÅ‚Ä…d poÅ‚Ä…czenia z LLM Ollama"
**RozwiÄ…zanie:**
```bash
# SprawdÅº czy Ollama dziaÅ‚a
ollama list
curl http://localhost:11434/api/tags

# JeÅ›li nie dziaÅ‚a, uruchom ponownie
ollama serve &
```

### Problem: "EasyOCR nie rozpoznaje tekstu"
**RozwiÄ…zanie:**
- SprawdÅº jakoÅ›Ä‡ zdjÄ™cia paragonu
- Lepsze oÅ›wietlenie, pÅ‚aska powierzchnia
- Ponownie zrÃ³b zdjÄ™cie

### Problem: "ModuleNotFoundError: No module named 'X'"
**RozwiÄ…zanie:**
```bash
# SprawdÅº czy Å›rodowisko wirtualne jest aktywne
source venv/bin/activate

# Zainstaluj brakujÄ…ce pakiety
pip install -r requirements.txt
```

### Problem: Aplikacja dziaÅ‚a wolno
**RozwiÄ…zanie:**
- **GPU**: Ustaw `"gpu": true` w `data/config.json` (jeÅ›li masz GPU)
- **CPU**: Model Bielik 1.5B jest zoptymalizowany pod CPU
- **RAM**: Zamknij niepotrzebne aplikacje

## ğŸ“ Funkcje bez LLM

JeÅ›li masz problemy z Ollama, aplikacja nadal dziaÅ‚a z ograniczonymi funkcjami:
- âœ… Dodawanie produktÃ³w (rÄ™czne kategoryzowanie)
- âœ… PrzeglÄ…danie spiÅ¼arni 
- âœ… ZarzÄ…dzanie produktami
- âœ… Statystyki
- âŒ Automatyczne kategoryzowanie
- âŒ Sugerowanie dat waÅ¼noÅ›ci
- âŒ Sugestie przepisÃ³w
- âŒ Parsowanie paragonÃ³w

## ğŸ†˜ Wsparcie

1. **SprawdÅº logi** - aplikacja wypisuje szczegÃ³Å‚owe bÅ‚Ä™dy
2. **SprawdÅº konfiguracjÄ™** - `data/config.json`
3. **SprawdÅº serwer Ollama** - `curl http://localhost:11434/api/tags`
4. **GitHub Issues** - zgÅ‚oÅ› problem w repozytorium

## ğŸ¯ WskazÃ³wki dla najlepszych rezultatÃ³w

### JakoÅ›Ä‡ zdjÄ™Ä‡ paragonÃ³w:
- **Dobre oÅ›wietlenie** (bez cieni)
- **PÅ‚aska powierzchnia** (bez zagiÄ™Ä‡)  
- **WyraÅºny tekst** (nie rozmazany)
- **CaÅ‚y paragon** w kadrze

### Optymalizacja wydajnoÅ›ci:
- WyÅ‚Ä…cz niepotrzebne aplikacje podczas przetwarzania OCR
- UÅ¼ywaj modelu Bielik 1.5B (juÅ¼ w konfiguracji)
- Regularnie archiwizuj stare produkty

### Codzienne uÅ¼ycie:
- **Rano**: SprawdÅº komunikaty o wygasajÄ…cych produktach
- **Po zakupach**: Dodaj paragon do folderu nowe/
- **Podczas gotowania**: UÅ¼yj wyszukiwania produktÃ³w (Opcja 5)
- **Planowanie**: Generuj przepisy (Opcja 6)